{
  "hash": "d747a7dfc7b477f13361c4197f92123a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: ETC4500/ETC5450 Advanced&nbsp;R&nbsp;programming\nauthor: \"Week 4: Debugging and profiing\"\nformat:\n  presentation-beamer:\n    fontsize: \"14pt,t\"\n    section-titles: false\n    knitr:\n      opts_chunk:\n        dev: \"cairo_pdf\"\n    fig-width: 7.5\n    fig-height: 3.5\n    include-in-header: ../header.tex\n    keep-tex: true\n---\n\n\n\n## Outline\n\n\\vspace*{0.4cm}\n\\tableofcontents\n\n# Debugging\n\n## Overall debugging strategy\n\n* Google\n* Stack Overflow\n* Posit Community\n* Create a minimal reproducible example\n* Create a unit test\n* Figure out where the test fails\n* Fix it and test\n\n## Minimal reproducible examples\n\n* A minimal data set. Use a small built-in dataset, or make a small example.\n* If you must include your own data, use `dput()`, but subset where possible.\n* The *minimal* amount of code to reproduce the problem. Load only necessary packages.\n* If the example involves random numbers, set the seed with `set.seed()`.\n* Information about package versions, R version, OS. Use `sessioninfo::session_info()`.\n\n## reprex\n\nThe **reprex** package helps create *minimal reproducible examples*.\n\n* Results are saved to clipboard in form that can be pasted into a GitHub issue, Stack Overflow question, or email.\n* `reprex::reprex()`: takes R code and outputs it in a markdown format.\n* Append session info via\\newline `reprex(..., session_info = TRUE)`.\n* Use the RStudio addin.\n\n\n## Debugging tools in R\n\\vspace*{-0.2cm}\n\\fontsize{14}{15}\\sf\n\n* `traceback`: prints out the function call stack after an error occurs; does nothing if there's no error.\n* `debug`: flags a function for \"debug\" mode which allows you to step through execution of a function one line at a time.\n* `undebug`: removes the \"debug\" flag from a function.\n* `browser`: pauses execution of a function and puts the function in debug mode.\n* `trace`: allows you to insert code into a function at a specific line number.\n* `untrace`: removes the code inserted by `trace`.\n* `recover`: allows you to modify the error behaviour so that you can browse the function call stack after an error occurs.\n\n## Traceback\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(a) g(a)\ng <- function(b) h(b)\nh <- function(c) i(c)\ni <- function(d) {\n  if (!is.numeric(d)) stop(\"`d` must be numeric\", call. = FALSE)\n  d + 10\n}\n```\n:::\n\n\\only<1>{\\includegraphics[width = 12cm]{../screenshots/debugging/rstudio-error.png}}\n\\only<2>{\\includegraphics[width = 12cm]{../screenshots/debugging/rstudio-traceback.png}}\n\\pause\\pause\n\n::: {.cell}\n\n```{.r .cell-code}\nf(\"a\")\n#> Error: `d` must be numeric\ntraceback()\n#> 5: stop(\"`d` must be numeric\", call. = FALSE) at debugging.R#6\n#> 4: i(c) at debugging.R#3\n#> 3: h(b) at debugging.R#2\n#> 2: g(a) at debugging.R#1\n#> 1: f(\"a\")\n```\n:::\n\n## Interactive debugging\n\\fontsize{13}{14}\\sf\n\n* Using `browser()`\n\n  ```r\n  i <- function(d) {\n    browser()\n    if (!is.numeric(d)) stop(\"`d` must be numeric\", call. = FALSE)\n    d + 10\n  }\n  ```\n\n* Setting breakpoints\n  * Similar to `browser()` but no change to source code.\n  * Set in RStudio by clicking to left of line number, or pressing `Shift+F9`.\n* `options(error = browser)`\n\n## Interactive debugging\n\n* `debug()` : inserts a `browser()` statement at start of function.\n* `undebug()` : removes `browser()` statement.\n* `debugonce()` : same as `debug()`, but removes `browser()` after first run.\n\n## Exercises\n\n1.  What's wrong with this code?\\fontsize{10}{10}\\sf\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Multivariate scaling function\n    mvscale <- function(object) {\n      # Remove centers\n      mat <- sweep(object, 2L, colMeans(object))\n      # Scale and rotate\n      S <- var(mat)\n      U <- chol(solve(S))\n      z <- mat %*% t(U)\n      # Return orthogonalized data\n      return(z)\n    }\n    mvscale(mtcars)\n    ```\n    \n    ::: {.cell-output .cell-output-error}\n    \n    ```\n    Error in mat %*% t(U): requires numeric/complex matrix/vector arguments\n    ```\n    \n    \n    :::\n    :::\n\n## Example\n\\vspace*{-0.15cm}\n\\centerline{\\href{https://posit.co/resources/videos/debugging-techniques-in-rstudio-2/}{\\includegraphics[width=16cm, height=20cm]{../screenshots/Amanda_Gadrow.png}}}\n\n## Common error messages\n\\fontsize{12}{13}\\sf\n\n* could not find function `\"xxxx\"`\n* object `xxxx` not found\n* cannot open the connection / No such file or directory\n* missing value where `TRUE` / `FALSE` needed\n* unexpected `=` in `\"xxxx\"`\n* attempt to apply non-function\n* undefined columns selected\n* subscript out of bounds\n* object of type 'closure' is not subsettable\n* `$` operator is invalid for atomic vectors\n* list object cannot be coerced to type 'double'\n* arguments imply differing number of rows\n* non-numeric argument to binary operator\n\n## Common warning messages\n\\fontsize{12}{13}\\sf\n\n* NAs introduced by coercion\n* replacement has `xx` rows to replace `yy` rows\n* number of items to replace is not a multiple of replacement length\n* the condition has length > 1 and only the first element will be used\n* longer object length is not a multiple of shorter object length\n* package is not available for R version `xx`\n\n## Non-interactive debugging\n\n* Necessary for debugging code that runs in a non-interactive environment.\n* Is the global environment different? Have you loaded different packages? Are objects left from previous sessions causing differences?\n* Is the working directory different?\n* Is the `PATH` environment variable, which determines where external commands (like `git`) are found, different?\n* Is the `R_LIBS` environment variable, which determines where `library()` looks for packages, different?\n\n## Non-interactive debugging\n\n* `dump.frame()` saves state of R session to file.\n\n  ```r\n  # In batch R process ----\n  dump_and_quit <- function() {\n    # Save debugging info to file last.dump.rda\n    dump.frames(to.file = TRUE)\n    # Quit R with error status\n    q(status = 1)\n  }\n  options(error = dump_and_quit)\n\n  # In a later interactive session ----\n  load(\"last.dump.rda\")\n  debugger()\n  ```\n\n* Last resort: `print()`: slow and primitive.\n\n## Other tricks\n\n* `sink()` : capture output to file.\n* `options(warn = 2)` : turn warnings into errors.\n* `rlang::with_abort()` : turn messages into errors.\n* If R or RStudio crashes, it is probably a bug in compiled code.\n* Post minimal reproducible example to Posit Community or Stack Overflow.\n\n# Measuring performance\n\n## Profiling functions\n\n* `Rprof()` : records every function call.\n* `summaryRprof()` : summarises the results.\n* `profvis()` : visualises the results.\n\n## Profiling\n\nWhere are the bottlenecks in your code?\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(profvis)\nlibrary(bench)\nf <- function() {\n  pause(0.1)\n  g()\n  h()\n}\ng <- function() {\n  pause(0.1)\n  h()\n}\nh <- function() {\n  pause(0.1)\n}\n```\n:::\n\n## Profiling\n\\fontsize{10}{10}\\sf\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp <- tempfile()\nRprof(tmp, interval = 0.1)\nf()\nRprof(NULL)\nwriteLines(readLines(tmp))\n#> sample.interval=100000\n#> \"pause\" \"g\" \"f\"\n#> \"pause\" \"h\" \"g\" \"f\"\n#> \"pause\" \"h\" \"f\"\n```\n:::\n\n## Profiling\n\\fontsize{10}{10}\\sf\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here::here(\"week4/profiling-example.R\"))\nprofvis(f())\n```\n:::\n\n\\vspace*{-0.5cm}\n\\centerline{\\includegraphics[width = 7cm]{../screenshots/performance/flamegraph.png}}\n\n## Microbenchmarking\n\\fontsize{10}{10}\\sf\n\n### `system.time()`\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rnorm(1e6)\nsystem.time(min(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  0.003   0.000   0.003 \n```\n\n\n:::\n\n```{.r .cell-code}\nsystem.time(sort(x)[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  0.129   0.006   0.135 \n```\n\n\n:::\n\n```{.r .cell-code}\nsystem.time(x[order(x)[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  0.087   0.000   0.086 \n```\n\n\n:::\n:::\n\n## Microbenchmarking\n\\fontsize{10}{10}\\sf\n\n### `bench::mark()`\n\n::: {.cell}\n\n```{.r .cell-code}\nbench::mark(\n  min(x),\n  sort(x)[1],\n  x[order(x)[1]]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 6\n  expression          min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>     <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 min(x)           1.26ms    1.5ms     603.         0B     0   \n2 sort(x)[1]      79.67ms   88.7ms      11.3   11.44MB     5.63\n3 x[order(x)[1]]  48.95ms   55.7ms      17.4    3.81MB     2.18\n```\n\n\n:::\n:::\n\n## Microbenchmarking\n\n* `mem_alloc` tells you the memory allocated in the first run.\n* `n_gc` tells you the total number of garbage collections over all runs.\n* `n_itr` tells you how many times the expression was evaluated.\n* Pay attention to the units!\n\n## Exercises\n\n2.  What's the fastest way to compute a square root? Compare:\n\n    - `sqrt(x)`\n    - `x^0.5`\n    - `exp(log(x) / 2)`\n\n    Use `system.time()` find the time for each operation.\n\n    Repeat using `bench::mark()`. Why are they different?\n\n# Improving performance\n\n## Vectorization\n\n* Vectorization is the process of converting a repeated operation into a vector operation.\n* The loops in a vectorized function are implemented in C instead of R.\n* Using `map()` or `apply()` is **not** vectorization.\n* Matrix operations are vectorized, and usually very fast.\n\n## Beware of over-vectorising\n\n* Change all missing values in a data frame to zero:\n\n  ::: {.cell}\n  \n  ```{.r .cell-code}\n  x[is.na(x)] <- 0\n  ```\n  :::\n\n  or\n\n  ::: {.cell}\n  \n  ```{.r .cell-code}\n  for(i in seq(NCOL(x))) {\n    x[is.na(x[, i]), i] <- 0\n  }\n  ```\n  :::\n\n  Why might the second approach be preferred?\n\n## Exercises\n\n3. Write the following algorithm to estimate $\\displaystyle\\int_0^1 x^2 dx$ using vectorized code\n\n### Monte Carlo Integration\n   a. Initialise: `hits = 0`\n   b. for i in 1:N\n      * Generate two random numbers,  $U_1, U_2$, between 0 and 1\n      * If $U_2 < U_1^2$, then `hits = hits + 1`\n   c. end for\n   d. Area estimate = hits/N\n\n# Caching\n\n## Caching: using rds\n\n::: {.cell}\n\n```{.r .cell-code}\nif (file.exists(\"results.rds\")) {\n  res <- readRDS(\"results.rds\")\n} else {\n  res <- compute_it()  # a time-consuming function\n  saveRDS(res, \"results.rds\")\n}\n```\n:::\n\n\\pause\\vspace*{1cm}\n\n\\alert{Equivalently\\dots}\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- xfun::cache_rds(\n  compute_it(), # a time-consuming function\n  file = \"results.rds\"\n)\n```\n:::\n\n## Caching: using rds\n\\fontsize{10}{10}\\sf\n\n::: {.cell freeze='false'}\n\n```{.r .cell-code}\ncompute <- function(...) {\n    xfun::cache_rds(rnorm(6), file = \"results.rds\", ...)\n}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.0773  2.3402 -0.3022 -0.4836 -0.2259  1.4893\n```\n\n\n:::\n\n```{.r .cell-code}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.0773  2.3402 -0.3022 -0.4836 -0.2259  1.4893\n```\n\n\n:::\n:::\n\n\n\n::: {.cell freeze='false'}\n\n```{.r .cell-code}\ncompute(rerun = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.467 -1.228  0.507 -0.365  0.937  0.893\n```\n\n\n:::\n\n```{.r .cell-code}\ncompute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.467 -1.228  0.507 -0.365  0.937  0.893\n```\n\n\n:::\n:::\n\n## Caching: Rmarkdown\n\n\n````{.default}\n```{r import-data, cache=TRUE}\nd <- read.csv('my-precious.csv')\n```\n\n```{r analysis, dependson='import-data', cache=TRUE}\nsummary(d)\n```\n````\n\n* Requires explicit dependencies or changes not detected.\n* Changes to functions or packages not detected.\n* Good practice to frequently clear cache to avoid problems.\n* targets is a better solution: Week 8\n\n## Caching: Quarto\n\n\n````{.default}\n```{r}\n#| label: import-data\n#| cache: true\nd <- read.csv('my-precious.csv')\n```\n\n```{r}\n#| label: analysis\n#| dependson: import-data\n#| cache: true\nsummary(d)\n```\n````\n\n* Same problems as Rmarkdown\n* targets is a better solution: Week 8\n\n## Caching: memoise\n\nCaching stores results of computations so they can be reused.\n\n\\fontsize{10}{10}\\sf\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(memoise)\nsq <- function(x) {\n  print(\"Computing square of 'x'\")\n  x**2\n}\nmemo_sq <- memoise(sq)\nmemo_sq(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Computing square of 'x'\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nmemo_sq(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n:::\n\n## Exercises\n\n4. Use `bench::mark()` to compare the speed of `sq()` and `memo_sq()`.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}